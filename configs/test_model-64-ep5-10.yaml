data:
    batch_size: 8
    n_patients: 50                  # Max patients to load
    pad_idx: 0                      # token index reserved for padding
    use_bfloat16: False             # use bfloat16 precision for training
model:
    embed_dim: 64
    num_heads: 2
    num_layers: 2
    ffn_dim: 256                    # 4 Ã— EMBED_DIM
    max_seq_len: 128                # positional embedding capacity
    predictor_hidden_dim: 128
optimization:
    epochs: 10
    base_lr: .001
    schedule: "linear"              # warmup_cosine - base_lr, ref_lr, warmup_epochs, T_max
                                    # linear - base_lr
                                    # linear_decay - base_lr, min_lr_ratio, total_steps
    tau: 0.996                      # EMA momentum
artifacts:
    tag: "model-64-ep5-10"          # unique tag (artifacts folder created under artifacts/runs)
    extract_embeddings: True        # disable embedding extraction
    extract_embeddings_every: 5     # extract embeddings every n epochs (if extract_embeddings is True)
    load_from_checkpoint: True
    checkpoint_every: 5
